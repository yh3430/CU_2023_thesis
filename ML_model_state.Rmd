---
title: "thesis_2"
author: "Yu He"
date: "2023-04-04"
output: html_document
---
# load libraries
```{r}
library(tidyverse)
library(haven)
library(caret)
library(cluster)
library(nnet)
library(broom)
library(pROC)
library(rpart.plot)
library(randomForest)
```
Variable list:

Demographic Factors:
a. Age
b. Sex
c. Grade
d. Race (race4)

Anthropometric Factors:
a. Height - remove
b. BMI
c. BMI Percentile - removed
d. Obesity Indicator (qnobese) - remove

Sexual Factors:
a. Sexual Identity (sexed) - remove
b. Birth Control Use (qnothhpl)
c. Sexual Orientation (Q66) - remove

Food Allergy:
a. Food Allergy (Qfoodallergy) - remove

Unintentional Injuries and Violence:
a. Physical fights (Q17)
b. Forced sexual activities (Q20) - remove
c. Dating-related forced sexual activities (Q21)
d. Bullying on school property (Q23)
e. Suicidal thoughts (Q26)

Tobacco Use:
a. Tried cigarette smoking (Q30)

Alcohol and Other Drug Use:
a. Alcohol consumption (Q41)
b. Marijuana use (Q47)
c. Prescription pain medicine misuse (Q49)
d. Cocaine use (Q50)
e. Heroin use (Q52)
f. Methamphetamine use (Q53)
g. Needle use for injecting illegal drugs (Q56) - remove

Risky Sexual Behavior:
a. Sexual intercourse (Q58) - remove
b. Number of sexual partners (Q61) - remove
c. Condom use (Q63)
d. Sexual contact with different genders (Q65)

Cognitive and Health Factors:
a. HIV testing (Q84) - remove
b. Asthma diagnosis (Q87)
c. School grades (Q89)

Outcome Variable:
a. STI testing other than HIV (Q85)


# to do list: 1, remove the variabe with 0 level like age. 2. make q50, q52, and q53 into 2 level factors?. 3 remove q84?. 4. check difference between postreample and compare_resample function


# Step 1, data proparing
## data import and process, save the processed sas7dbat data into csv file to improve R runnig time. Only run one time.
```{r}
# set path
setwd("~/Desktop/CU Spring 2023/master thesis II2/CU_2023_yu")

# load state data a_m
#df_a_m = read_sas("./data/sadc_2019_state_a_m.sas7bdat") %>% 
#  janitor::clean_names() %>% 
#  select(sitename, year, age, sex, grade, race4, bmi, qnothhpl, q85, 
#         q17, q21, q23, q26, q30, q41, q47, q49, q50, q52, q53, q63, q65, q87, q89
#         )

# save the data as a CSV file
# write.csv(df_a_m, "./data/df_a_m.csv", row.names = FALSE)

# load state data n_z
#df_n_z = read_sas("./data/sadc_2019_state_n_z.sas7bdat") %>% 
#  janitor::clean_names() %>% 
#  select(sitename, year, age, sex, grade, race4, bmi, qnothhpl, q85, 
#         q17, q21, q23, q26, q30, q41, q47, q49, q50, q52, q53, q63, q65, q87, q89)

# save the data as a CSV file
#write.csv(df_n_z, "./data/df_n_z.csv", row.names = FALSE)

# load school district data 
#df_district = read_sas("./data/sadc_2019_district.sas7bdat") %>% 
#  janitor::clean_names() %>% 
#   select(sitename, year, age, sex, grade, race4, bmi, qnothhpl, q85, 
#        q17, q21, q23, q26, q30, q41, q47, q49, q50, q52, q53, q63, q65, q87, q89)

# save the data as a CSV file
#write.csv(df_district, "./data/df_district.csv", row.names = FALSE)
```

## import the processed data
```{r}
# load the processed  state data
df_part1 = read_csv("./data/df_a_m.csv")
df_part2 = read_csv("./data/df_n_z.csv")

# merge two state dataset
df_f_project = bind_rows(df_part1, df_part2)

# load the district dataset
df_district = read_csv("./data/df_district.csv")
```


## data cleaning
```{r}
# the state data
df_fit_state <- 
  df_f_project %>% 
  filter(year == 2019) %>% 
  mutate(
  across(c("sex", "age", "grade", "race4", "qnothhpl"), as.factor),
  year = as.character(year)
  ) %>% 
  mutate_at(vars(starts_with("q")), as.factor) %>% 
  filter(q85 %in% c(1, 2, 3)) %>% 
  na.omit()

# the school distrcit data
df_fit_district <- 
  df_district %>% 
  filter(year == 2019) %>%
    mutate(
  across(c("sex", "age", "grade", "race4", "qnothhpl"), as.factor),
  year = as.character(year)
  ) %>% 
  mutate_at(vars(starts_with("q")), as.factor) %>%
  filter(q85 %in% c(1, 2, 3)) %>% 
  na.omit()

df_fit_state %>% 
  group_by(sitename) %>% 
  summarize(
    n_obs = n()
  )

df_fit_district %>% 
  group_by(sitename) %>% 
  summarize(
    n_obs = n()
  )

summary(df_fit_district)
summary(df_fit_state)
```



## check variables with 0 variance levels and re-create new variables for un-balanced variables
```{r}
# the modification for school district data
levels(df_fit_district$age)
levels(df_fit_district$q63)
levels(df_fit_district$q65)

# drop the level with 0
df_fit_district = df_fit_district %>% 
  # Remove levels from the factor column
  filter(!(age %in% c("1", "2"))) %>% 
  filter(q63 != 1) %>% 
  filter(q65 != 1) %>% 
  mutate(
  # Remove the unused levels from the factor column
     age = factor(age),
     q63 = factor(q63),
     q65 = factor(q65),
  # cover q50, q52, q53 to two level variables
  # 1 = 1, and 2 = the rest of observations
     q50 = ifelse(q50 == 1, 1, 2),
     q50 = factor(q50),
     q52 = ifelse(q52 == 1, 1, 2),
     q52 = factor(q52),
     q53 = ifelse(q53 == 1, 1, 2),
     q53 = factor(q53)
  ) 

summary(df_fit_district)


# the modification for state data
levels(df_fit_state$age)
levels(df_fit_state$q63)
levels(df_fit_state$q65)

# drop the level with 0
df_fit_state = df_fit_state %>% 
  # Remove levels from the factor column
  filter(age != 1) %>% 
  filter(q63 != 1) %>% 
  filter(q65 != 1) %>% 
  mutate(
  # Remove the unused levels from the factor column
     age = factor(age),
     q63 = factor(q63),
     q65 = factor(q65),
  # cover q50, q52, q53 to two level variables
  # 1 = 1, and 2 = the rest of observations
     q50 = ifelse(q50 == 1, 1, 2),
     q50 = factor(q50),
     q52 = ifelse(q52 == 1, 1, 2),
     q52 = factor(q52),
     q53 = ifelse(q53 == 1, 1, 2),
     q53 = factor(q53)
  ) 

summary(df_fit_state)
```



```{r}
# Check for missing values
missing_vals_1 <- is.na(df_fit_district)

# Count the number of missing values in each column
colSums(missing_vals_1)

# Check for missing values
missing_vals_2 <- is.na(df_fit_state)

# Count the number of missing values in each column
colSums(missing_vals_2)
```


# Step 2, fit the multinominal logistic regression
## first try to fit on the whole data, ignore clustered by sitename for now.
```{r}
df_state_lr <- df_fit_state %>%
  select(-year)

# Fit the model using the cleaned dataset
model <- multinom(q85 ~ ., data = df_state_lr)

summary_model = summary(model)

# Get a tidy version of the model output
tidy_model <- tidy(model)

# Set the significance level
alpha <- 0.05

# Find significant variables based on the p-value
significant_vars <- tidy_model$p.value < alpha

# Print the significant variables
significant_results <- tidy_model[significant_vars, ]
print(significant_results)
```


## fit multinominal logistic regression for every disctrict
```{r}
# Define a function to fit the multinom model for each site
fit_multinom_for_site_d <- function(site, data) {
  df_site <- data %>%
    filter(sitename == site) %>%
    select(-sitename) %>%
    select(-year)
  
  # Fit the model using the cleaned dataset
  model <- multinom(q85 ~ ., data = df_site)
  
  summary_model <- summary(model)
  tidy_model <- tidy(model)
  
  # Set the significance level
  alpha <- 0.05
  
  # Find significant variables based on the p-value
  significant_vars <- tidy_model$p.value < alpha
  
  # Print the significant variables
  significant_results <- tidy_model[significant_vars, ]
  return(list(site = site, significant_results = significant_results))
}

# Get the unique site names from the dataset
unique_sites_d <- unique(df_fit_district$sitename)

# Fit the multinom model for each site
models_by_site <- lapply(unique_sites_d, fit_multinom_for_site_d, data = df_fit_district)

# Display the results
print(models_by_site)
```


## fit multinominal logistic regression for every state
```{r}
# Define a function to fit the multinom model for each site
fit_multinom_for_site_s <- function(site, data) {
  df_site <- data %>%
    filter(sitename == site) %>%
    select(-sitename) %>%
    select(-year)
  
  # Fit the model using the cleaned dataset
  model <- multinom(q85 ~ ., data = df_site)
  
  summary_model <- summary(model)
  tidy_model <- tidy(model)
  
  # Set the significance level
  alpha <- 0.05
  
  # Find significant variables based on the p-value
  significant_vars <- tidy_model$p.value < alpha
  
  # Print the significant variables
  significant_results <- tidy_model[significant_vars, ]
  return(list(site = site, significant_results = significant_results))
}

# Get the unique site names from the dataset
unique_sites_s <- unique(df_fit_state$sitename)

# Fit the multinom model for each site
models_by_site <- lapply(unique_sites_s, fit_multinom_for_site_s, data = df_fit_state)

# Display the results
print(models_by_site)
```

# Step 3, fit the data with multinominal logistic regression, random forest, SVM, Elastic Net, ridge, lasso regression, and classification tree
## We use the distrcit data as training dataset, and state data as testing data

```{r}
df_state_train <- df_fit_state %>%
  select(-year)

summary(df_state_train)
```

## fit the multinominal logistic regression
```{r}
set.seed(123)
# 10-fold cross-validation
ctrl <- trainControl(method = "cv", number = 10, sampling = "up")

# Fit the model using the cleaned dataset
model_multinom <- train(q85 ~ .,
              data = df_state_train,      
              method = "multinom",   
              trControl = ctrl,     
              preProcess = c("center", "scale"))

# check the results of the model
summary(model_multinom)
confusionMatrix(model_multinom)
model_multinom$results

varImp(model_multinom)

multinom_outcome <- predict(model_multinom, df_state_train, type = "raw")

# Create confusion matrix
multinom_evaluation <- confusionMatrix(multinom_outcome, df_state_train$q85)
multinom_evaluation
```

## fit the random forest
```{r}
#ntree = 100
#set.seed(123)
# Setting 5-fold cross-validation for fast demonstration.
#control_settings <- trainControl(method = "cv", number = 10, sampling = "up")

# Trying three different values of mtry
#mtry_vals_rf <- c(ncol(df_state_train)-1, 
#                 sqrt(ncol(df_state_train)-1), 
#                  0.5*ncol(df_state_train)-1)
#mtry_grid_rf<- expand.grid(.mtry = round(mtry_vals_rf))

#model_rf <- train(q85 ~., data = df_state_train, 
#                  method = "rf", metric = "Accuracy", 
#                  preProc=c("center", "scale"),
#                  tuneGrid = mtry_grid_rf, 
#                  trControl = control_settings, ntree = 100)

#confusionMatrix(model_rf)
#model_rf$results
#model_rf$bestTune
#model_rf$finalModel

#varImp(model_rf)
```


```{r}
# ntree = 200
#set.seed(123)
# Setting 5-fold cross-validation for fast demonstration.
#control_settings <- trainControl(method = "cv", number = 10, sampling = "up")

# Trying three different values of mtry
#mtry_vals_rf <- c(ncol(df_state_train)-1, 
#                  sqrt(ncol(df_state_train)-1), 
#                  0.5*ncol(df_state_train)-1)
#mtry_grid_rf<- expand.grid(.mtry = round(mtry_vals_rf))

#model_rf <- train(q85 ~., data = df_state_train, 
#                  method = "rf", metric = "Accuracy", 
#                  preProc=c("center", "scale"),
#                  tuneGrid = mtry_grid_rf, 
#                  trControl = control_settings, ntree = 200)

#confusionMatrix(model_rf)
#model_rf$results
#model_rf$bestTune
#model_rf$finalModel

#varImp(model_rf)

#rf_outcome <- predict(model_rf, df_state_train, type = "raw")
#confusionMatrix(rf_outcome, df_state_train$q85)
```

## ntree = 400 give the best results
```{r}
 ntree = 400
set.seed(123)
# Setting 5-fold cross-validation for fast demonstration.
control_settings <- trainControl(method = "cv", number = 10, sampling = "up")

# Trying three different values of mtry
mtry_vals_rf <- c(ncol(df_state_train)-1, 
                  sqrt(ncol(df_state_train)-1), 
                  0.5*ncol(df_state_train)-1)
mtry_grid_rf<- expand.grid(.mtry = round(mtry_vals_rf))

model_rf <- train(q85 ~., data = df_state_train, 
                  method = "rf", metric = "Accuracy", 
                  preProc=c("center", "scale"),
                  tuneGrid = mtry_grid_rf, 
                  trControl = control_settings, ntree = 400)

confusionMatrix(model_rf)
model_rf$results
model_rf$bestTune
model_rf$finalModel

varImp(model_rf)

rf_outcome <- predict(model_rf, df_state_train, type = "raw")
confusionMatrix(rf_outcome, df_state_train$q85)
```


## fit the SVM
```{r}
set.seed(123)

# Specify training control
train_control_svc <- trainControl(method = "cv", number = 10, sampling = "up")

# Create tuning grid
grid_svc <- expand.grid(C = seq(0.001, 2, length = 30))

# Train model with cross-validation and tuning
# Incorporate different values for cost (C)
model_svc <- train(q85 ~ ., 
                   data = df_state_train, 
                   method = "svmLinear",  
                   trControl = train_control_svc, 
                   preProcess = c("center", "scale"), 
                   tuneGrid = grid_svc)

model_svc$bestTune
model_svc$results
#Visualize accuracy versus values of C
plot(model_svc)

#Obtain metrics of accuracy from training
confusionMatrix(model_svc)

#See information about final model
model_svc$finalModel

# varImp(model_svc)

svm_outcome <- predict(model_svc, df_state_train, type = "raw")
confusionMatrix(svm_outcome, df_state_train$q85)
```


## fit the lasso regression
```{r}
set.seed(123)
#Create grid to search lambda
lambda <- 10^seq(-3,3, length = 100)

# Specify training control
train_control_lasso <- trainControl(method = "cv", number = 10)

model_lasso = train(q85 ~.,
                    df_state_train, 
                    method = "glmnet", 
                    trControl = train_control_lasso, 
                    tuneGrid = expand.grid(alpha = 1, lambda = lambda))

summary(model_lasso)
model_lasso$bestTune
model_lasso$results

#Visualize accuracy versus values of C
plot(model_lasso)

#Obtain metrics of accuracy from training
confusionMatrix(model_lasso)

varImp(model_lasso)
plot(varImp(model_lasso))

lasso_outcome <- predict(model_lasso, df_state_train, type = "raw")
confusionMatrix(lasso_outcome, df_state_train$q85)
```


## fit the ridge regression
```{r}
set.seed(123)
#Create grid to search lambda
lambda <- 10^seq(-3,3, length = 100)

# Specify training control
train_control_ridge <- trainControl(method = "cv", number = 10)

model_ridge = train(q85 ~.,
                    df_state_train, 
                    method = "glmnet", 
                    trControl = train_control_ridge, 
                    tuneGrid = expand.grid(alpha = 0, lambda = lambda))

summary(model_ridge)
model_ridge$bestTune
model_ridge$results

#Visualize accuracy versus values of C
plot(model_ridge)

#Obtain metrics of accuracy from training
confusionMatrix(model_ridge)

varImp(model_ridge)

ridge_outcome <- predict(model_ridge, df_state_train, type = "raw")
confusionMatrix(ridge_outcome, df_state_train$q85)
```


## fit the Elastic Net method
```{r}
# model 2, chooses alpha and lambda via cross-validation using all of the features - Elastic Net method
set.seed(123)

# Construct k-folds in your data
trcontrol = trainControl(method = "cv", number = 10)

# model 2 fit
model_elastic_net <- train(q85 ~., 
                     data = df_state_train, 
                     method = "glmnet",
                     trControl = trcontrol, 
                     preProc=c("center", "scale"), 
                     tuneLength = 10, metric = "Accuracy"
  )

# Print the values of alpha and lambda that gave best prediction
model_elastic_net$bestTune

# Print all of the options examined
model_elastic_net$results

# Model coefficients
coef(model_elastic_net$finalModel, model_elastic_net$bestTune$lambda)

# visualization and accuracy
varImp(model_elastic_net)
plot(varImp(model_elastic_net))
confusionMatrix(model_elastic_net)

elastic_net_outcome <- predict(model_elastic_net, df_state_train, type = "raw")
confusionMatrix(elastic_net_outcome, df_state_train$q85)
```


## fit the classfication Tree model
```{r}
set.seed(123)

#Using 10-fold cross-validation to train model
train_control_tree <- trainControl(method = "cv", number = 10, sampling = "up")

#Create sequence of cp parameters to try 
grid_tree <- expand.grid(cp = seq(0.001, 0.3, by = 0.01))

#Using rpart method to generate regression tree, using all variables in dataset to predict life expectancy
model_tree <- train(q85 ~ . , 
                     data = df_state_train, 
                     method = "rpart", 
                     trControl = train_control_tree, 
                     tuneGrid = grid_tree)

model_tree$bestTune
model_tree$results

#Can use rpart.plot function to visualize tree
rpart.plot(model_tree$finalModel)

#Note you can obtain variable importance on the final model within training data
varImp(model_tree)

tree_outcome <- predict(model_tree, df_state_train, type = "raw")
confusionMatrix(tree_outcome, df_state_train$q85)
```


# Step 4, evaluation and best model selection - multinominal logistic regression, random forest, SVM, classfication Tree, Elastic Net, ridge, lasso regression, and classification tree
```{r}
# model multinominal logistic regression
multinom_outcome <- predict(model_multinom, df_state_train, type = "raw")
multinom_evaluation <- confusionMatrix(multinom_outcome, df_state_train$q85, positive = "1")
multinom_evaluation

# model random forest
rf_outcome <- predict(model_rf, df_state_train, type = "raw")
rf_evaluation <- confusionMatrix(rf_outcome, df_state_train$q85, positive = "1")
rf_evaluation

# model SVM
svm_outcome <- predict(model_svc, df_state_train, type = "raw")
svm_evaluation <- confusionMatrix(svm_outcome, df_state_train$q85, positive = "1")
svm_evaluation

# model lasso
lasso_outcome <- predict(model_lasso, df_state_train, type = "raw")
lasso_evaluation <- confusionMatrix(lasso_outcome, df_state_train$q85, positive = "1")
lasso_evaluation

# model ridge
ridge_outcome <- predict(model_ridge, df_state_train, type = "raw")
ridge_evaluation <- confusionMatrix(ridge_outcome, df_state_train$q85, positive = "1")
ridge_evaluation

# model elastic net
elastic_net_outcome <- predict(model_elastic_net, df_state_train, type = "raw")
elastic_net_evaluation <- confusionMatrix(elastic_net_outcome, df_state_train$q85, positive = "1")
elastic_net_evaluation

# model classification tree
tree_outcome <- predict(model_tree, df_state_train, type = "raw")
tree_evaluation <- confusionMatrix(tree_outcome, df_state_train$q85, positive = "1")
tree_evaluation
```


```{r}
# Accuracy and 95% CI plot
compare_resamp <- resamples(list(
  multinom = model_multinom,
  random_forest = model_rf,
  SVM = model_svc,
  lasso = model_lasso,
  ridge = model_ridge,
  elastic_net = model_elastic_net,
  cla_tree = model_tree
))

summary(compare_resamp)
dotplot(compare_resamp)
```


```{r}
# create table of accuracy and kappa
postResample(multinom_outcome, df_state_train$q85)
postResample(rf_outcome, df_state_train$q85)
postResample(svm_outcome, df_state_train$q85)
postResample(lasso_outcome, df_state_train$q85)
postResample(ridge_outcome, df_state_train$q85)
postResample(elastic_net_outcome, df_state_train$q85)
postResample(tree_outcome, df_state_train$q85)
```


# Step 5, Best tuned model applied on testing dataset - the state data
```{r}

# model random forest
rf_outcome_test <- predict(model_rf, df_state_train, type = "raw")
rf_evaluation_test <- confusionMatrix(rf_outcome_test, df_state_train$q85, positive = "1")
rf_evaluation_test

postResample(rf_outcome_test, df_state_train$q85)
```

# Step 6, run the best random forest model for every school district
```{r}
# Get unique values of sitname
unique_sitenames <- unique(df_state_train$sitename)

# Initialize a list to store the results for each sitename
results <- list()

# Run the analysis for each sitname
for (sitename in unique_sitenames) {
  # Subset the data for the current sitname
  df_train_sitename <- df_state_train[df_state_train$sitename == sitename, ]
  
  # Train the Random Forest model
  model_rf <- randomForest(q85 ~ ., data = df_train_sitename)
  
  # Make predictions on the test dataset
  rf_outcome_test <- predict(model_rf, df_train_sitename, type = "response")
  
  # Evaluate the model using the confusionMatrix function
  rf_evaluation_test <- confusionMatrix(rf_outcome_test, df_train_sitename$q85, positive = "1")
  
  # Calculate performance metrics using the postResample function
  performance_metrics <- postResample(rf_outcome_test, df_train_sitename$q85)
  
  # Get variable importance
  variable_importance <- varImp(model_rf)
  
  # Store the results for the current sitname in the results list
  results[[sitename]] <- list(
    "ConfusionMatrix" = rf_evaluation_test,
    "PerformanceMetrics" = performance_metrics,
    "VariableImportance" = variable_importance
  )
}

# Print the results
print(results)
```

## use ridge regression method
```{r}
set.seed(123)

# Create grid to search lambda
lambda <- 10^seq(-3, 3, length = 100)

# Specify training control
train_control_ridge <- trainControl(method = "cv", number = 10)

# Get unique values of sitename
unique_sitenames <- unique(df_state_train$sitename)

# Initialize a list to store the results for each sitename
results <- list()

# Run the analysis for each sitename
for (sitename in unique_sitenames) {
  # Subset the data for the current sitename
  df_train_sitename <- df_state_train[df_state_train$sitename == sitename, ]
  
  # Remove the 'sitename' column from the dataframe
  df_train_sitename <- df_train_sitename %>% select(-sitename)
  
  # Train Ridge Regression model
  model_ridge <- train(q85 ~ .,
                       df_train_sitename,
                       method = "glmnet",
                       trControl = train_control_ridge,
                       tuneGrid = expand.grid(alpha = 0, lambda = lambda))
  
  # Make predictions on the training dataset
  ridge_outcome <- predict(model_ridge, df_train_sitename, type = "raw")
  
  # Obtain metrics of accuracy from training
  cm_ridge <- confusionMatrix(ridge_outcome, df_train_sitename$q85)
  
  # Variable importance
  ridge_varImp <- varImp(model_ridge)
  
  # Store the results for the current sitename in the results list
  results[[sitename]] <- list(
    "BestTune" = model_ridge$bestTune,
    "Results" = model_ridge$results,
    "ConfusionMatrix" = cm_ridge,
    "VariableImportance" = ridge_varImp
  )
}

# Print the results
print(results)


```


```{r}
df_state_train
```

```{r}
df_al = df_state_train %>% 
  filter(sitename == "Alabama (AL)") %>% 
  select(-sitename)


set.seed(123)
#Create grid to search lambda
lambda <- 10^seq(-3,3, length = 100)

# Specify training control
train_control_ridge <- trainControl(method = "cv", number = 10)

model_ridge = train(q85 ~.,
                    df_al, 
                    method = "glmnet", 
                    trControl = train_control_ridge, 
                    tuneGrid = expand.grid(alpha = 0, lambda = lambda))

summary(model_ridge)
model_ridge$bestTune
model_ridge$results

#Visualize accuracy versus values of C
plot(model_ridge)

#Obtain metrics of accuracy from training
confusionMatrix(model_ridge)

varImp(model_ridge)

ridge_outcome <- predict(model_ridge, df_state_train, type = "raw")
confusionMatrix(ridge_outcome, df_state_train$q85)
```











